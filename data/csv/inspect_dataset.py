#!/usr/bin/env python3
"""
Simple Dataset Inspector - No dependencies required
Check archive-2 dataset structure and compatibility
"""

import csv
from datetime import datetime, timedelta
from collections import defaultdict

print("="*70)
print("        DATASET INSPECTOR - ARCHIVE-2")
print("="*70)

# Paths
TRAIN_PATH = "data/csv/archive-2/train.csv"
MEAL_PATH = "data/csv/archive-2/meal_info.csv"

# Step 1: Analyze train.csv
print("\nüìä Analyzing train.csv...")
with open(TRAIN_PATH, 'r') as f:
    reader = csv.DictReader(f)
    rows = list(reader)
    
print(f"   ‚Ä¢ Total records: {len(rows):,}")
print(f"   ‚Ä¢ Columns: {', '.join(rows[0].keys())}")
print(f"\n   First 5 records:")
for i, row in enumerate(rows[:5], 1):
    print(f"   {i}. Week {row['week']}, Meal {row['meal_id']}, Orders: {row['num_orders']}")

# Analyze weeks
weeks = set(int(row['week']) for row in rows)
print(f"\n   ‚Ä¢ Week range: {min(weeks)} to {max(weeks)} ({len(weeks)} weeks)")
print(f"   ‚Ä¢ Approximate years: {len(weeks)/52:.1f} years")

# Analyze meals
meals = set(row['meal_id'] for row in rows)
print(f"   ‚Ä¢ Unique meals: {len(meals)}")

# Analyze orders
orders = [int(row['num_orders']) for row in rows]
print(f"   ‚Ä¢ Total orders: {sum(orders):,}")
print(f"   ‚Ä¢ Average orders per record: {sum(orders)/len(orders):.1f}")
print(f"   ‚Ä¢ Max orders in a record: {max(orders):,}")

# Step 2: Analyze meal_info.csv
print("\nüçΩÔ∏è  Analyzing meal_info.csv...")
with open(MEAL_PATH, 'r') as f:
    reader = csv.DictReader(f)
    meals_info = list(reader)

print(f"   ‚Ä¢ Total meals: {len(meals_info)}")
print(f"\n   Meal categories:")
categories = defaultdict(int)
cuisines = defaultdict(int)
for meal in meals_info:
    categories[meal['category']] += 1
    cuisines[meal['cuisine']] += 1

for cat, count in sorted(categories.items()):
    print(f"      ‚Ä¢ {cat}: {count} meals")

print(f"\n   Cuisines:")
for cui, count in sorted(cuisines.items()):
    print(f"      ‚Ä¢ {cui}: {count} meals")

# Step 3: Check compatibility
print("\n‚úÖ COMPATIBILITY CHECK:")
print("\n   Current system requires:")
print("      ‚Ä¢ date (datetime)")
print("      ‚Ä¢ dish_name (string)")
print("      ‚Ä¢ quantity_sold (integer)")

print("\n   Archive-2 dataset has:")
print("      ‚úì week (can convert to date)")
print("      ‚úì meal_id (can join with meal_info to get name)")
print("      ‚úì num_orders (= quantity_sold)")
print("      ‚úì EXTRA: prices, promotions, center_id")

print("\n   üìù Conversion needed:")
print("      1. week ‚Üí date (week 1 = 2022-01-03)")
print("      2. meal_id ‚Üí dish_name (category + cuisine)")
print("      3. num_orders ‚Üí quantity_sold")

print("\n   üí° Recommended conversion:")
print("      ‚Ä¢ Original: 456,549 records")
print("      ‚Ä¢ After aggregation by (date, dish): ~7,395 records")
print(f"      ‚Ä¢ ({len(weeks)} weeks √ó {len(meals_info)} meals)")

print("\n" + "="*70)
print("‚úÖ DATASET IS COMPATIBLE!")
print("="*70)
print("\nüìù To convert:")
print("   1. Install dependencies: pip3 install pandas")
print("   2. Run: python3 data/csv/convert_archive2_advanced.py")
print("   3. Output: data/csv/orders_real.csv")
print("")
