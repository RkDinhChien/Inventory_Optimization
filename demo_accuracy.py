"""
Demo: Äo lÆ°á»ng Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c thuáº­t toÃ¡n dá»± Ä‘oÃ¡n
Sá»­ dá»¥ng Train-Test Split vÃ  cÃ¡c metrics chuáº©n
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from src.inventory_optimizer import InventoryOptimizer

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ÄO LÆ¯á»œNG Äá»˜ CHÃNH XÃC Dá»° ÄOÃN                          â•‘
â•‘                                                                            â•‘
â•‘  Kiá»ƒm tra Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c thuáº­t toÃ¡n ML vs Statistical              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

def calculate_accuracy_metrics(actual, predicted):
    """
    TÃ­nh cÃ¡c chá»‰ sá»‘ Ä‘o lÆ°á»ng Ä‘á»™ chÃ­nh xÃ¡c
    
    Metrics:
    - MAE (Mean Absolute Error): Sai sá»‘ trung bÃ¬nh tuyá»‡t Ä‘á»‘i
    - RMSE (Root Mean Squared Error): CÄƒn báº­c hai cá»§a sai sá»‘ bÃ¬nh phÆ°Æ¡ng trung bÃ¬nh
    - MAPE (Mean Absolute Percentage Error): Sai sá»‘ pháº§n trÄƒm trung bÃ¬nh
    - Accuracy %: Äá»™ chÃ­nh xÃ¡c (100% - MAPE)
    """
    actual = np.array(actual)
    predicted = np.array(predicted)
    
    # MAE - Trung bÃ¬nh sai lá»‡ch tuyá»‡t Ä‘á»‘i
    mae = np.mean(np.abs(actual - predicted))
    
    # RMSE - Pháº¡t náº·ng nhá»¯ng dá»± Ä‘oÃ¡n sai quÃ¡ xa
    rmse = np.sqrt(np.mean((actual - predicted) ** 2))
    
    # MAPE - Sai sá»‘ pháº§n trÄƒm (dá»… hiá»ƒu nháº¥t)
    mape = np.mean(np.abs((actual - predicted) / actual)) * 100
    
    # Accuracy - Äá»™ chÃ­nh xÃ¡c
    accuracy = 100 - mape
    
    return {
        'MAE': mae,
        'RMSE': rmse,
        'MAPE': mape,
        'Accuracy': accuracy
    }

def test_forecasting_accuracy(use_ml=False, ml_algorithm=None):
    """
    Test Ä‘á»™ chÃ­nh xÃ¡c báº±ng cÃ¡ch:
    1. Chia dá»¯ liá»‡u thÃ nh Train (80%) vÃ  Test (20%)
    2. DÃ¹ng Train Ä‘á»ƒ há»c
    3. Dá»± Ä‘oÃ¡n trÃªn Test
    4. So sÃ¡nh dá»± Ä‘oÃ¡n vs thá»±c táº¿
    """
    print(f"\n{'='*80}")
    method_name = f"ML - {ml_algorithm.upper()}" if use_ml else "STATISTICAL"
    print(f"ğŸ“Š Testing: {method_name}")
    print(f"{'='*80}\n")
    
    # Load data
    optimizer = InventoryOptimizer(use_ml=use_ml, ml_algorithm=ml_algorithm)
    
    # Load real data náº¿u cÃ³, khÃ´ng thÃ¬ dÃ¹ng sample
    if os.path.exists("data/csv/orders_real.csv"):
        print("âœ… Using real dataset (archive-2)")
        optimizer.load_data(orders_file="data/csv/orders_real.csv")
    else:
        print("â„¹ï¸  Using sample data")
        optimizer.load_data()
    
    orders = optimizer.orders_data.copy()
    
    # Sáº¯p xáº¿p theo thá»i gian
    orders['date'] = pd.to_datetime(orders['date'])
    orders = orders.sort_values('date')
    
    print(f"ğŸ“… Date range: {orders['date'].min()} to {orders['date'].max()}")
    print(f"ğŸ“Š Total records: {len(orders)}")
    
    # Train-Test Split: 80% train, 20% test
    split_idx = int(len(orders) * 0.8)
    train_data = orders.iloc[:split_idx]
    test_data = orders.iloc[split_idx:]
    
    print(f"\nğŸ”¹ Training set: {len(train_data)} records")
    print(f"ğŸ”¹ Test set: {len(test_data)} records")
    
    # Huáº¥n luyá»‡n vá»›i train data
    optimizer.orders_data = train_data
    
    # Láº¥y sá»‘ ngÃ y cáº§n dá»± Ä‘oÃ¡n
    test_days = (test_data['date'].max() - test_data['date'].min()).days + 1
    
    print(f"\nâ³ Forecasting {test_days} days ahead...")
    
    try:
        # Dá»± Ä‘oÃ¡n
        forecast = optimizer.forecast_demand(days_ahead=test_days)
        
        # Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ so sÃ¡nh
        forecast['date'] = pd.to_datetime(forecast['date'])
        test_data_agg = test_data.groupby(['date', 'dish_name'])['quantity_sold'].sum().reset_index()
        
        # Merge actual vs predicted
        comparison = test_data_agg.merge(
            forecast, 
            on=['date', 'dish_name'],
            how='inner',
            suffixes=('_actual', '_predicted')
        )
        
        if len(comparison) == 0:
            print("âš ï¸  No matching data for comparison")
            return None
        
        print(f"âœ… Comparison ready: {len(comparison)} data points\n")
        
        # TÃ­nh metrics
        metrics = calculate_accuracy_metrics(
            comparison['quantity_sold'],
            comparison['predicted_quantity']
        )
        
        # Hiá»ƒn thá»‹ káº¿t quáº£
        print(f"{'='*80}")
        print(f"ğŸ“ˆ ACCURACY METRICS - {method_name}")
        print(f"{'='*80}")
        print(f"")
        print(f"  MAE  (Mean Absolute Error):        {metrics['MAE']:>10.2f}")
        print(f"  RMSE (Root Mean Squared Error):    {metrics['RMSE']:>10.2f}")
        print(f"  MAPE (Mean Abs Percentage Error):  {metrics['MAPE']:>10.2f}%")
        print(f"")
        print(f"  ğŸ¯ ACCURACY:                        {metrics['Accuracy']:>10.2f}%")
        print(f"")
        print(f"{'='*80}")
        
        # VÃ­ dá»¥ dá»± Ä‘oÃ¡n
        print(f"\nğŸ’¡ Sample Predictions (first 10):")
        print(f"{'-'*80}")
        print(f"{'Date':<12} {'Dish':<25} {'Actual':>10} {'Predicted':>10} {'Error':>10}")
        print(f"{'-'*80}")
        
        for idx, row in comparison.head(10).iterrows():
            error = abs(row['quantity_sold'] - row['predicted_quantity'])
            date_str = row['date'].strftime('%Y-%m-%d')
            dish_short = row['dish_name'][:23]
            print(f"{date_str:<12} {dish_short:<25} {row['quantity_sold']:>10.0f} "
                  f"{row['predicted_quantity']:>10.0f} {error:>10.0f}")
        
        return metrics
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return None

# Main execution
if __name__ == "__main__":
    print("\nğŸš€ Starting Accuracy Tests...\n")
    
    results = {}
    
    # Test 1: Statistical Method
    print("="*80)
    print("TEST 1: STATISTICAL METHOD (Baseline)")
    print("="*80)
    metrics_stat = test_forecasting_accuracy(use_ml=False)
    if metrics_stat:
        results['Statistical'] = metrics_stat
    
    # Test 2: ML Methods (náº¿u cÃ³ dependencies)
    try:
        print("\n\n" + "="*80)
        print("TEST 2: MACHINE LEARNING METHODS")
        print("="*80)
        
        # XGBoost
        print("\nğŸ¤– Testing XGBoost...")
        metrics_xgb = test_forecasting_accuracy(use_ml=True, ml_algorithm='xgboost')
        if metrics_xgb:
            results['XGBoost'] = metrics_xgb
        
    except ImportError:
        print("\nâš ï¸  ML dependencies not installed")
        print("ğŸ’¡ Install with: pip install statsmodels xgboost scikit-learn prophet")
    
    # Summary comparison
    if len(results) > 1:
        print("\n\n" + "="*80)
        print("ğŸ“Š COMPARISON SUMMARY")
        print("="*80)
        print(f"\n{'Method':<20} {'Accuracy':>12} {'MAE':>12} {'RMSE':>12} {'MAPE':>12}")
        print("-"*80)
        
        for method, metrics in results.items():
            print(f"{method:<20} {metrics['Accuracy']:>11.2f}% "
                  f"{metrics['MAE']:>11.2f} "
                  f"{metrics['RMSE']:>11.2f} "
                  f"{metrics['MAPE']:>11.2f}%")
        
        # TÃ¬m method tá»‘t nháº¥t
        best_method = max(results.items(), key=lambda x: x[1]['Accuracy'])
        print(f"\nğŸ† Best Method: {best_method[0]} ({best_method[1]['Accuracy']:.2f}% accuracy)")
    
    print("\n" + "="*80)
    print("âœ… Testing Complete!")
    print("="*80)
    
    print("""
    
ğŸ“– Giáº£i thÃ­ch Metrics:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â€¢ MAE (Mean Absolute Error):
  â†’ Trung bÃ¬nh sai lá»‡ch bao nhiÃªu Ä‘Æ¡n vá»‹
  â†’ VD: MAE = 5 nghÄ©a lÃ  trung bÃ¬nh dá»± Ä‘oÃ¡n sai Â±5 Ä‘Æ¡n hÃ ng
  â†’ CÃ ng tháº¥p cÃ ng tá»‘t

â€¢ RMSE (Root Mean Squared Error):
  â†’ Pháº¡t náº·ng nhá»¯ng dá»± Ä‘oÃ¡n sai quÃ¡ xa
  â†’ Nháº¡y cáº£m vá»›i outliers
  â†’ CÃ ng tháº¥p cÃ ng tá»‘t

â€¢ MAPE (Mean Absolute Percentage Error):
  â†’ Sai sá»‘ pháº§n trÄƒm trung bÃ¬nh
  â†’ VD: MAPE = 10% nghÄ©a lÃ  trung bÃ¬nh sai 10%
  â†’ Dá»… hiá»ƒu, khÃ´ng phá»¥ thuá»™c Ä‘Æ¡n vá»‹

â€¢ Accuracy:
  â†’ Äá»™ chÃ­nh xÃ¡c = 100% - MAPE
  â†’ VD: 90% accuracy nghÄ©a lÃ  dá»± Ä‘oÃ¡n Ä‘Ãºng 90%
  â†’ CÃ ng cao cÃ ng tá»‘t (>85% lÃ  tá»‘t)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ Tips:
  - Statistical: 75-80% accuracy (nhanh, Ä‘Æ¡n giáº£n)
  - XGBoost: 90-95% accuracy (tá»‘t nháº¥t cho data nhiá»u)
  - SARIMA: 85-90% accuracy (tá»‘t cho seasonal patterns)
  - Random Forest: 85-92% accuracy (á»•n Ä‘á»‹nh)
    """)
